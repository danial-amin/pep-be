# ============================================
# PEP - Persona Generator API Configuration
# ============================================
# Copy this file to .env and fill in your values
# Required variables are marked with [REQUIRED]

# ============================================
# Database Configuration
# ============================================
# PostgreSQL database connection
# [REQUIRED] Full database URL
DATABASE_URL=postgresql://pep_user:pep_password@localhost:5432/pep_db

# Optional: Individual database settings (used if DATABASE_URL not provided)
POSTGRES_USER=pep_user
POSTGRES_PASSWORD=pep_password
POSTGRES_DB=pep_db

# ============================================
# Vector Database Configuration
# ============================================
# Choose between "pinecone" (recommended) or "chroma" (local development)
VECTOR_DB_TYPE=pinecone

# Pinecone Configuration (for production/free tier)
# [REQUIRED if VECTOR_DB_TYPE=pinecone]
PINECONE_API_KEY=your_pinecone_api_key_here
# Environment/region: "us-east-1-aws", "gcp-starter" (free tier), or "us-west1-gcp"
PINECONE_ENVIRONMENT=us-east-1-aws
# Index name (will be created automatically if it doesn't exist)
PINECONE_INDEX_NAME=pep-documents
# Auto-recreate index if dimension mismatch (WARNING: deletes all vectors)
# AUTO_RECREATE_INDEX=false

# ChromaDB Configuration (for local development only)
# Only used if VECTOR_DB_TYPE=chroma
CHROMA_HOST=localhost
CHROMA_PORT=8000

# ============================================
# OpenAI Configuration
# ============================================
# [REQUIRED] Your OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Model configuration (defaults shown)
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# ============================================
# Document Processing Configuration
# ============================================
# Optional: Adjust these if you have different rate limits or token limits
# MAX_TOKENS_PER_CHUNK=20000  # Max tokens per processing chunk
# CHUNK_OVERLAP_TOKENS=500     # Overlap between chunks
# PROCESSING_DELAY_SECONDS=2.0 # Delay between chunk processing (seconds)

# ============================================
# Application Configuration
# ============================================
# Environment: "development" or "production"
ENVIRONMENT=development

# Logging level: "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
LOG_LEVEL=INFO

# CORS origins (comma-separated list, or "*" for all)
# For production, specify actual origins: "http://localhost:3000,https://yourdomain.com"
CORS_ORIGINS=*

# ============================================
# File Upload Configuration
# ============================================
# Maximum file upload size in bytes (default: 10MB)
# MAX_UPLOAD_SIZE=10485760

# Allowed file extensions (comma-separated)
# ALLOWED_EXTENSIONS=.pdf,.docx,.txt,.md

# ============================================
# Image Generation Configuration
# ============================================
# Image generation service (currently only "openai" is supported)
IMAGE_GENERATION_SERVICE=openai

# ============================================
# Langfuse Observability Configuration
# ============================================
# Langfuse provides observability and tracking for LLM calls
# 
# Option 1: Use Langfuse Cloud (https://cloud.langfuse.com)
# Option 2: Self-host on Railway (see langfuse-railway/README.md)
#
# MULTI-PROJECT SUPPORT:
# You can use the same Langfuse instance for multiple projects!
# Each project gets its own API keys. See LANGFUSE_MULTI_PROJECT.md for details.
#
# [OPTIONAL] Set to false to disable Langfuse tracking
LANGFUSE_ENABLED=true

# [REQUIRED if LANGFUSE_ENABLED=true] Your Langfuse public key
# Get from: Langfuse Dashboard → Select Project → Settings → API Keys
# Each project has its own keys - use the keys for THIS project
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here

# [REQUIRED if LANGFUSE_ENABLED=true] Your Langfuse secret key
# Get from: Langfuse Dashboard → Select Project → Settings → API Keys
# Each project has its own keys - use the keys for THIS project
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here

# Langfuse host URL (same for all projects using the same instance)
# For cloud: https://cloud.langfuse.com
# For self-hosted on Railway: https://your-langfuse-service.railway.app
# NOTE: All projects using the same Langfuse instance use the same HOST
LANGFUSE_HOST=https://cloud.langfuse.com

# ============================================
# Frontend Configuration (for frontend .env)
# ============================================
# This is for the frontend React app, not the backend
# VITE_API_URL=http://localhost:8080/api/v1
